name: "Approve self-hosted runner scale set creation/update request"
on:
  issue_comment:
    types: [created]

jobs:
  prechecks:
    name: "Check pre-conditions for self hosted runner scale set creation/update"
    if: github.event.issue.pull_request != null && startsWith(github.event.issue.title, 'Create or edit self hosted runner scale set for env ') && startsWith(github.event.comment.body, '/approve')
    runs-on: Linux
    outputs:
      environment: ${{ steps.prechecks.outputs.environment }}
    steps:
    - name: Debug
      uses: actions/github-script@v3
      with:
        script: console.log(JSON.stringify(context, null, 2));
    - name: Check permissions and scan environment
      id: prechecks
      uses: actions/github-script@v3
      env:
        title: ${{ github.event.issue.title }}
        comment: ${{ github.event.issue.body }}
      with:
        github-token: ${{secrets.GITHUB_TOKEN}}
        script: |
          const { title } = process.env;
          let envMatch = title.match(/^Create or edit self hosted runner scale set for env ([a-zA-Z0-9_]+)$/)
          if(!envMatch || envMatch[1].trim() === '') {
            message = 'ðŸ‘‹  @' + context.actor + ', seems as if you have not specified an environment in the issue title, please make sure to follow the issue template for self hosted runner scale set creation and updates.'
            core.setOutput('error', message)
            throw new Error(message)
          }
          const environment = envMatch[1]
          core.info("environment: " + environment)
          const permissionRes = await github.repos.getCollaboratorPermissionLevel(
            {
              ...context.repo,
              username: context.actor
            }
          )
          if (permissionRes.status !== 200) {
            message = 'Permission check returns non-200 status: ${permissionRes.status}'
            core.setOutput('error', message)
            throw new Error(message)
          }
          const actorPermission = permissionRes.data.permission
          if (!['admin', 'write'].includes(actorPermission)) {
              message = 'ðŸ‘‹  @' + context.actor + ', seems as if you have not admin/write permission to /approve this PR, permissions: ${actorPermission}'
              core.setOutput('error', message)
              throw new Error(message)
          }
          core.setOutput('environment', environment)

    - name: Pre-Check-Failed
      id: precheck-failed
      if: failure()
      uses: actions/github-script@v3
      env:
        message: ${{steps.prechecks.outputs.error}}
      with:
        github-token: ${{secrets.GITHUB_TOKEN}}
        script: |
          const { message } = process.env;
          github.issues.createComment({
            ...context.repo,
            issue_number: context.issue.number,
            body: message
          })

  act-on-provisioning-request:
    name: "Provision self hosted runner scale set"
    needs: [prechecks]

    env:
      TF_VAR_github_app_client_secret: ${{ secrets.APP_CLIENT_SECRET }}
      TF_VAR_github_app_key_base64: ${{ secrets.APP_KEY_BASE64 }}
      TF_VAR_github_app_id: ${{ secrets.APP_ID }}
      TF_VAR_github_app_client_id: ${{ secrets.APP_CLIENT_ID }}
      TF_VAR_github_enterprise_url: ${{ secrets.ENTERPRISE_SERVER_URL }}
      TF_IN_AUTOMATION: true
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      environment: ${{needs.prechecks.outputs.environment}}

    timeout-minutes: 10

    runs-on: Linux
    steps:

      - name: Acknowledge self hosted runner provisioning request
        id: acknowledge
        uses: actions/github-script@v3
        with:
          github-token: ${{secrets.GITHUB_TOKEN}}
          script: |
            const log_url = `${process.env.GITHUB_SERVER_URL}/${context.repo.owner}/${context.repo.repo}/actions/runs/${process.env.GITHUB_RUN_ID}`
            const { environment } = process.env;
            pr = await github.pulls.get(
              {
                ...context.repo,
                pull_number: context.issue.number
              }
            )

            if (pr.status !== 200) {
              message = 'Could not retrieve PR info: ${permissionRes.status}'
              core.setOutput('error', message)
              throw new Error(message)
            }

            if (!pr.data.mergeable) {
              message = 'This PR is currently not mergeable, please update it with the latest changes from the target branch.'
              core.setOutput('error', message)
              throw new Error(message)
            }

            github.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: 'ðŸ‘‹  @' + context.actor + ' provisioning self hosted runner scale set environment ' + environment + ' now, you can watch the progress [here](' + log_url + ') ...'
            })

            core.setOutput('ref', pr.data.head.ref)

      - name: Checkout
        uses: actions/checkout@v2
        with:
          ref: ${{ steps.acknowledge.outputs.ref }}

      - name: Setup node
        uses: actions/setup-node@v2.1.2
        with:
          node-version: '12'

      - name: HashiCorp - Setup Terraform
        uses: hashicorp/setup-terraform@v1.3.2
        with:
          terraform_version: 0.14.5
          terraform_wrapper: true

      - name: Terraform Init lambdas-download
        id: init-lambdas
        run: cd actions-runner-envs/download-lambdas && terraform init

      - name: Terraform Plan lambdas-download
        id: plan-lambdas
        run: cd actions-runner-envs/download-lambdas && terraform plan -no-color -out lambdas-download.plan
        continue-on-error: false

      - name: Terraform Apply lambdas-download
        id: apply
        run: cd actions-runner-envs/download-lambdas && terraform apply -no-color -input=false -auto-approve lambdas-download.plan
        continue-on-error: false

      - name: Terraform Init AWS environment
        id: init-aws
        run:  cd actions-runner-envs/$environment && terraform init

      - name: Terraform Plan AWS environment
        id: plan-aws
        run: cd actions-runner-envs/$environment && terraform plan -no-color -out ${environment}.plan
        continue-on-error: false

      - name: Terraform Apply AWS environment changes
        id: apply-changes
        run: |
          cd actions-runner-envs/$environment
          IFS=";" SAMPLE_WORKFLOW=$(cat test-auto-scaling-workflow.yml)
          SAMPLE_WORKFLOW="${SAMPLE_WORKFLOW//'%'/'%25'}"
          SAMPLE_WORKFLOW="${SAMPLE_WORKFLOW//$'\n'/'%0A'}"
          SAMPLE_WORKFLOW="${SAMPLE_WORKFLOW//$'\r'/'%0D'}"
          echo "::set-output name=sample-workflow::$SAMPLE_WORKFLOW"

          terraform apply -no-color -input=false -auto-approve ${environment}.plan
        continue-on-error: false

      - name: Terraform Retrieve Webhook config
        id: retrieve-webhook-config
        run: cd actions-runner-envs/$environment && terraform output webhook

      - name: Provisioning Succeeded
        id: provisioning-succeeded
        if: success()
        uses: actions/github-script@v3
        env:
          CONFIG_APPLIED: ${{ steps.apply-changes.outputs.stdout }}
          SAMPLE_WORKFLOW: ${{ steps.apply-changes.outputs.sample-workflow }}
          WEBHOOK_DETAILS: ${{ steps.retrieve-webhook-config.outputs.stdout }}
          PLAN: ${{ steps.plan-aws.outputs.stdout }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const commentBody = `\
            ### :computer: Self-hosted runner configuration applied successfully :runner:

            In order to make use of the configuration, [install this GitHub app](https://octodemo.com/github-apps/terraform-aws-github-runner/installations/new) in your org and create an org webhook to send the \`check_run\` event and set the following parameters:
            ${process.env.WEBHOOK_DETAILS}

            <details>
            <summary>ðŸ“– Terraform plan</summary>

            \`\`\`
            ${process.env.PLAN}
            \`\`\`
            </details>

            <details>

            <summary>ðŸš€ Plan applied</summary>

            \`\`\`
            ${process.env.CONFIG_APPLIED}
            \`\`\`
            </details>

            <details>
            <summary>:octocat: Auto-scaling test workflow (paste into .github/workflows directory of target repo)</summary>

            \`\`\`
            ${process.env.SAMPLE_WORKFLOW}
            \`\`\`
            </details>

            Merging this PR now ...

            After merging, you can also copy the GitHub Action sample workflow from [here](../blob/master/actions-runner-envs/${{needs.prechecks.outputs.environment}}/test-auto-scaling-workflow.yml).
            To change or delete the runner scale set configuration, open another issue, or reopen the last issue with a modified description.
            `;

            await github.issues.createComment({
              ...context.repo,
              issue_number: ${{ github.event.issue.number }},
              body: commentBody
            })

            github.pulls.merge({
              ...context.repo,
              pull_number: context.issue.number
            });

      - name: Provisioning Failed
        id: provisioning-failed
        if: cancelled() || failure()
        uses: actions/github-script@v3
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const log_url = `${process.env.GITHUB_SERVER_URL}/${context.repo.owner}/${context.repo.repo}/actions/runs/${process.env.GITHUB_RUN_ID}`

            github.issues.createComment({
              ...context.repo,
              issue_number: ${{ github.event.issue.number }},
              body: `Self-hosted runner provision request failed :cry:. [View error logs](${ log_url}).`
            })


      # Force an unlock on the Terraform state file if we were cancelled or failed (probably really only needed for cancelled).
      - name: Reveal Terraform Lock
        id: reveal_terraform_lock
        if: cancelled() || failure()
        run: cd actions-runner-envs/$environment && terraform force-unlock -force abc
        continue-on-error: true

      - name: Extract Terraform Lock ID
        if: cancelled() || failure()
        id: extract_lock
        uses: actions/github-script@v3
        env:
          TERRAFORM_LOCK_OUTPUT: ${{ steps.reveal_terraform_lock.outputs.stderr }}
        with:
          lock_data: ${{ steps.reveal_terraform_lock.outputs.stderr }}
          script: >
            console.log(process.env.TERRAFORM_LOCK_OUTPUT);
            console.log(core.getInput('lock_data'));

            const matched = /Lock Info:\s*ID:\s*([a-z|0-9|-]*)/gm.exec(core.getInput('lock_data'));
            if (matched) {
              core.setOutput('lock_id', matched[1]);
            }
            core.setOutput('requires_unlock', !!matched);

      - name: Unlock Terraform State
        id: unlock_terraform_state
        if: (cancelled() || failure()) && steps.extract_lock.outputs.requires_unlock == 'true'
        run: cd actions-runner-envs/$environment && terraform force-unlock -force ${{ steps.extract_lock.outputs.lock_id }}
